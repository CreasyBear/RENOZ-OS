#!/usr/bin/env python3
"""
Regenerate meta files from current PRD JSONs.
Scans all *.prd.json files and produces accurate statistics.
"""

import json
import os
import glob
from datetime import datetime
from collections import defaultdict

PRD_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

def load_all_prds():
    """Load all PRD JSON files."""
    prds = []
    prd_files = glob.glob(os.path.join(PRD_ROOT, "**/*.prd.json"), recursive=True)

    for f in prd_files:
        try:
            with open(f) as fp:
                data = json.load(fp)
                data['_file'] = os.path.relpath(f, PRD_ROOT)
                data['_dir'] = os.path.dirname(os.path.relpath(f, PRD_ROOT))
                prds.append(data)
        except Exception as e:
            print(f"Warning: Could not load {f}: {e}")

    return prds

def analyze_prds(prds):
    """Analyze PRD corpus and return statistics."""
    stats = {
        'total_prds': len(prds),
        'total_stories': 0,
        'total_iterations': 0,
        'by_phase': defaultdict(lambda: {'prds': 0, 'stories': 0, 'iterations': 0}),
        'by_type': defaultdict(int),
        'by_status': defaultdict(int),
        'dependencies': [],
        'stories_list': [],
    }

    for prd in prds:
        phase = prd.get('phase', 'unknown')
        stories = prd.get('stories', [])

        stats['by_phase'][phase]['prds'] += 1
        stats['by_phase'][phase]['stories'] += len(stories)

        for story in stories:
            stats['total_stories'] += 1
            est_iter = story.get('estimated_iterations', 3)
            stats['total_iterations'] += est_iter
            stats['by_phase'][phase]['iterations'] += est_iter

            story_type = story.get('type', 'unknown')
            stats['by_type'][story_type] += 1

            status = story.get('status', 'pending')
            stats['by_status'][status] += 1

            deps = story.get('dependencies', [])
            if deps:
                stats['dependencies'].append({
                    'story': story.get('id', 'unknown'),
                    'depends_on': deps,
                    'prd': prd.get('id', 'unknown'),
                })

            stats['stories_list'].append({
                'id': story.get('id', 'unknown'),
                'name': story.get('name', 'unknown'),
                'type': story_type,
                'iterations': est_iter,
                'prd': prd.get('id', 'unknown'),
                'phase': phase,
                'dependencies': deps,
            })

    return stats

def generate_atomization_summary(stats, prds):
    """Generate atomization-summary.md content."""
    today = datetime.now().strftime("%Y-%m-%d")

    lines = [
        "# PRD Atomization Summary",
        "",
        f"> **Generated**: {today}",
        f"> **Total PRDs**: {stats['total_prds']}",
        f"> **Total Stories**: {stats['total_stories']}",
        f"> **Total Estimated Iterations**: {stats['total_iterations']}",
        "",
        "---",
        "",
        "## Phase Summary",
        "",
        "| Phase | PRDs | Stories | Est. Iterations |",
        "|-------|------|---------|-----------------|",
    ]

    phase_order = ['foundation', 'domain', 'integration', 'role', 'workflow', 'cross-cutting', 'refactoring', 'unknown']
    for phase in phase_order:
        if phase in stats['by_phase']:
            p = stats['by_phase'][phase]
            lines.append(f"| {phase} | {p['prds']} | {p['stories']} | {p['iterations']} |")

    lines.extend([
        "",
        "---",
        "",
        "## Story Type Distribution",
        "",
        "| Type | Count | Percentage |",
        "|------|-------|------------|",
    ])

    for stype, count in sorted(stats['by_type'].items(), key=lambda x: -x[1]):
        pct = (count / stats['total_stories'] * 100) if stats['total_stories'] > 0 else 0
        lines.append(f"| {stype} | {count} | {pct:.1f}% |")

    lines.extend([
        "",
        "---",
        "",
        "## PRD Details",
        "",
        "| PRD | Phase | Stories | Iterations | File |",
        "|-----|-------|---------|------------|------|",
    ])

    for prd in sorted(prds, key=lambda x: (x.get('phase', 'z'), x.get('id', ''))):
        stories = prd.get('stories', [])
        total_iter = sum(s.get('estimated_iterations', 3) for s in stories)
        lines.append(f"| {prd.get('id', 'unknown')} | {prd.get('phase', 'unknown')} | {len(stories)} | {total_iter} | `{prd.get('_file', '')}` |")

    lines.extend([
        "",
        "---",
        "",
        f"*Generated by regenerate_meta.py on {today}*",
    ])

    return "\n".join(lines)

def main():
    print("Loading PRDs...")
    prds = load_all_prds()
    print(f"Found {len(prds)} PRD files")

    print("Analyzing...")
    stats = analyze_prds(prds)

    print("\n=== Summary ===")
    print(f"Total PRDs: {stats['total_prds']}")
    print(f"Total Stories: {stats['total_stories']}")
    print(f"Total Estimated Iterations: {stats['total_iterations']}")
    print(f"\nBy Phase:")
    for phase, data in sorted(stats['by_phase'].items()):
        print(f"  {phase}: {data['prds']} PRDs, {data['stories']} stories, {data['iterations']} iterations")

    print(f"\nBy Type:")
    for stype, count in sorted(stats['by_type'].items(), key=lambda x: -x[1])[:10]:
        print(f"  {stype}: {count}")

    # Generate atomization summary
    summary = generate_atomization_summary(stats, prds)
    output_path = os.path.join(PRD_ROOT, "_meta", "atomization-summary.md")
    with open(output_path, 'w') as f:
        f.write(summary)
    print(f"\nWrote: {output_path}")

    return stats

if __name__ == "__main__":
    main()
